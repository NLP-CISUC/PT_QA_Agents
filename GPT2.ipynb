{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# GPT2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "AwzKHdQOujoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# receives\n",
        "# .txt file containing a list of question-answer pairs identified by 'P: ' and 'R: '\n",
        "# .txt file with a list of questions, one question per line\n",
        "\n",
        "# or\n",
        "\n",
        "# .txt file containing raw text\n",
        "# .txt file with a list of questions, one question per line\n",
        "\n",
        "# retrieves\n",
        "# .txt file containing the posed questions and respective GPT-2's answers, identified by 'P: ' and 'R: '"
      ],
      "metadata": {
        "id": "BGFSHRE5usf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n",
        "pip install gpt-2-simple"
      ],
      "metadata": {
        "id": "pItCdIrmuRTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "gpt2.download_gpt2(model_name = \"355M\")"
      ],
      "metadata": {
        "id": "TJRgZscVuVqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file management\n",
        "def open_file(filename):\n",
        "    read_file = open(filename, 'r')\n",
        "    file_cont = read_file.readlines()\n",
        "    read_file.close()\n",
        "\n",
        "    return file_cont\n",
        "\n",
        "def write_file(filename, content):\n",
        "    file_write = open(filename, 'w')\n",
        "    file_write.writelines(content)\n",
        "    file_write.close()"
      ],
      "metadata": {
        "id": "sza-_bwDuXnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8ZlR0pTuvYt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2iaCvqR9YBg"
      },
      "outputs": [],
      "source": [
        "# finetunes GPT-2 355M model\n",
        "def finetune_gpt2(domain_file_path, run_name, steps):\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    gpt2.finetune(sess, \n",
        "                dataset = domain_file_path,\n",
        "                model_name = '355M',\n",
        "                steps = steps,\n",
        "                run_name = run_name,\n",
        "                print_every = 10,\n",
        "                sample_every = 100\n",
        "                )\n",
        "    \n",
        "    print('GPT-2 Finetune Complete')\n",
        "    return sess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieves a file with the posed questions and GPT2's answers\n",
        "def retrieve_ans(domain_type, sess, run_name, questions_file_path, save_file_path):\n",
        "    count = 0\n",
        "    questions = open_file(questions_file_path)\n",
        "    responses = []\n",
        "\n",
        "    for question in questions:\n",
        "        # adds identifiers as a prefix\n",
        "        if domain_type == 'faqs':\n",
        "            ques_prefix = 'P: ' + question + 'R: '\n",
        "            include_prefix = True\n",
        "            \n",
        "        elif domain_type == 'text':\n",
        "            ques_prefix = question\n",
        "            include_prefix = False\n",
        "\n",
        "        # answer generation\n",
        "        answer = gpt2.generate(sess = sess,\n",
        "                run_name = run_name,\n",
        "                # the higher the temperature, the higher the randomness in generation\n",
        "                temperature = 0.2,\n",
        "                prefix = ques_prefix,\n",
        "                include_prefix = include_prefix,\n",
        "                truncate = '\\n\\n',\n",
        "                nsamples = 1,\n",
        "                return_as_list = True)[0]\n",
        "\n",
        "        if domain_type == 'faqs':\n",
        "             with open(save_file_path, 'a') as f:\n",
        "                f.write(answer)\n",
        "                f.write('\\n')\n",
        "                f.write('\\n')\n",
        "\n",
        "        elif domain_type == 'text':\n",
        "            aux_ques = 'P: ' +  question\n",
        "            aux_res = 'R: ' + answer\n",
        "            \n",
        "            with open(save_file_path, 'a') as f:  \n",
        "                f.write(aux_ques)\n",
        "                f.write(aux_res)\n",
        "                f.write('\\n')\n",
        "                f.write('\\n')\n",
        "\n",
        "        count += 1\n",
        "        print('Answer %d retrieved!' % count)\n",
        "\n",
        "    print('File with posed questions and respective answers created!')"
      ],
      "metadata": {
        "id": "YmsH1U4dEz5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES\n",
        "\n",
        "# domain_file_path - path to the file containing the domain\n",
        "# can be a file containing question-answer pairs identified with 'P: ' and 'R: ', respectively or a file containing raw text\n",
        "# FAQs                      # Text\n",
        "# P: question1              # Paragraph1Line1\n",
        "# R: answer1                # Paragraph1Line2\n",
        "# \\n                        # \\n\n",
        "# P: question2              # Paragraph2Line1\n",
        "# R: answer2                # Paragraph2Line2\n",
        "# \\n                        # \\n\n",
        "# must be a .txt file\n",
        "\n",
        "# run_name - name for gpt-2 finetuning session\n",
        "# used to continue finetuning from a given step\n",
        "\n",
        "# steps - number of steps to perform finetuning\n",
        "\n",
        "# domain_type - 'faqs', for a list of question-answer pairs identified with 'P: ' and 'R: '\n",
        "# domain_type - 'text', for a file containing unstructred raw text\n",
        "\n",
        "# questions_file_path - path to the file containing all questions, one question per line\n",
        "# Q1\n",
        "# Q2\n",
        "# Q3\n",
        "# ...\n",
        "# must be a .txt file\n",
        "\n",
        "# save_file_path - path to the file where the posed questions and respective retrieved answers are to be saved"
      ],
      "metadata": {
        "id": "mfX7S2irudyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = # 'run_name'\n",
        "steps = # steps\n",
        "domain_type = # 'faqs' or 'text'\n",
        "\n",
        "domain_file_path = # 'domain_file_path'\n",
        "input_questions_file_path = # 'input_questions_file_path'\n",
        "save_file_path = # 'save_file_path'\n",
        "\n",
        "sess = finetune_gpt2(domain_file_path, run_name, steps)\n",
        "retrieve_ans('faqs', sess, run_name, questions_file_path, saving_file_path)"
      ],
      "metadata": {
        "id": "ndzh0tDcEinM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}