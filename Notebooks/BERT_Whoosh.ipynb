{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Whoosh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# BERT + Whoosh\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ip-WrJxLygN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeFKrp9SyDA-"
      },
      "outputs": [],
      "source": [
        "# receives\n",
        "# a list of .txt files containing raw text\n",
        "# .txt file with a list of questions, one question per line\n",
        "\n",
        "# retrieves\n",
        "# .txt file containing the posed questions and respective BERT's answers, identified by 'P: ' and 'R: '"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "TvuTLWgWy0Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install whoosh"
      ],
      "metadata": {
        "id": "dDigpYjWol9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "from whoosh.index import create_in\n",
        "from whoosh.fields import *\n",
        "from whoosh.qparser import QueryParser\n",
        "from whoosh import qparser"
      ],
      "metadata": {
        "id": "WrYw1sU3y1d5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file management\n",
        "def open_file(filename):\n",
        "    read_file = open(filename, 'r')\n",
        "    file_cont = read_file.readlines()\n",
        "    read_file.close()\n",
        "\n",
        "    return file_cont\n",
        "\n",
        "def write_file(filename, content):\n",
        "    file_write = open(filename, 'w')\n",
        "    file_write.writelines(content)\n",
        "    file_write.close()"
      ],
      "metadata": {
        "id": "gXgJdcNmy579"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HnE2X4Riy7gF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21230142-4cd1-4c65-de98-05a831c528eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT - question answering pipeline\n",
        "def bert_model_qa(model_name, pipeline_name):\n",
        "    pipe_ques_answering = pipeline(pipeline_name, model=model_name)\n",
        "    return pipe_ques_answering\n",
        "\n",
        "def get_answer_qa(context, question, pipe_ques_answering):\n",
        "    result = pipe_ques_answering(question=question, context=context)\n",
        "\n",
        "    return result\n",
        "\n",
        "pipe_ques_answering = bert_model_qa('pierreguillou/bert-base-cased-squad-v1.1-portuguese', \"question-answering\")\n",
        "print('Question Answering Model Downloaded')"
      ],
      "metadata": {
        "id": "bv0alfiVy9ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# context management\n",
        "def format_context(context_list):\n",
        "    context = ''\n",
        "    for i in range(len(context_list)):\n",
        "        context = context + context_list[i]\n",
        "    return context"
      ],
      "metadata": {
        "id": "FTiaaAtAy-4e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve answer from BERT-QA\n",
        "def get_bert_answer(context_file_path, question, pipe_ques_answering):\n",
        "    context_list = open_file(context_file_path)\n",
        "    text_context = format_context(context_list)\n",
        "    result = get_answer_qa(text_context, question, pipe_ques_answering)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4W2S2n5f0oY7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates an index and writer objects, to add documents to be searched\n",
        "def create_index_writer(files_paths, files_names, ix_path):\n",
        "\n",
        "    # n-gram filter(2-3)\n",
        "    schema = Schema(title = TEXT, path = ID(stored = True), content = NGRAM(minsize = 2, maxsize = 3, stored = True))\n",
        "\n",
        "    # creates whoosh index\n",
        "    ix = create_in(ix_path, schema)\n",
        "\n",
        "    # creates writer object to add documents to be searched\n",
        "    writer = ix.writer()\n",
        "\n",
        "    # adds documents to writer object\n",
        "    for i in range(len(files_names)):\n",
        "\n",
        "        # get content from file\n",
        "        aux_content = format_context(files_paths[i])\n",
        "\n",
        "        # adds a document containing the content of a text file\n",
        "        writer.add_document(title = files_names[i], path = files_paths[i], content = aux_content)\n",
        "    writer.commit()\n",
        "\n",
        "    return ix"
      ],
      "metadata": {
        "id": "OMPY88DqzVK4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # retrieves the path of the document most similar to the posed question\n",
        "def most_similar_doc(ix, question):\n",
        "    path = ''\n",
        "\n",
        "    with ix.searcher() as searcher:\n",
        "\n",
        "        # creates query and search objects and finds most similar document\n",
        "        og = qparser.OrGroup.factory(0.9)\n",
        "        parser = qparser.QueryParser('content', ix.schema, group=og)\n",
        "        query = parser.parse(question)\n",
        "\n",
        "        s = ix.searcher()\n",
        "        results = s.search(query, limit = 1)\n",
        "\n",
        "        if len(results) > 0:\n",
        "            result = results[0]\n",
        "            path = result[\"path\"]\n",
        "\n",
        "    return path"
      ],
      "metadata": {
        "id": "ENSciWAUzkat"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieves a file with the posed questions and BERT's answers\n",
        "def bert_answers_score(files_paths, files_names, ix_path, questions_file_path, save_file_path, pipe_ques_answering):\n",
        "    questions = open_file(questions_file_path)\n",
        "    final_file_content = []\n",
        "\n",
        "    # create whyoosh index\n",
        "    ix = create_index_writer(files_paths, files_names, ix_path)\n",
        "\n",
        "    for question in questions:\n",
        "        # path of the most similar document\n",
        "        path = most_similar_doc(ix, question)\n",
        "\n",
        "        aux_q = question.replace('\\n', '')\n",
        "        answer = get_bert_answer(path, aux_q, pipe_ques_answering)\n",
        "\n",
        "        # creates the final file containing all posed questions and respective retrieved answers, with 'P: ' and 'R: ' identifiers\n",
        "        aux_q_2 = 'P: ' + question\n",
        "        final_file_content.append(aux_q_2)\n",
        "        aux_ans = 'R: ' + answer['answer']\n",
        "        final_file_content.append(aux_ans)\n",
        "        final_file_content.append('\\n')\n",
        "        final_file_content.append('\\n')\n",
        "\n",
        "\n",
        "    write_file(save_file_path, final_file_content)\n",
        "    print('File with posed questions and respective answers created!')"
      ],
      "metadata": {
        "id": "XCUuolC50bld"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES\n",
        "\n",
        "# files_paths - list with paths of files in domain\n",
        "# files_names - list with names of files in domain\n",
        "# position of each list must match\n",
        "\n",
        "# must be a collection of files containing raw text\n",
        "# Text\n",
        "# Paragraph1Line1\n",
        "# Paragraph1Line2\n",
        "# \\n                       \n",
        "# Paragraph2Line1\n",
        "# Paragraph2Line2\n",
        "# \\n                        \n",
        "# must be a .txt file                     \n",
        "\n",
        "# ix_path - path where the index object is to be saved\n",
        "\n",
        "# questions_file_path - path to the file containing all questions, one question per line\n",
        "# Q1\n",
        "# Q2\n",
        "# Q3\n",
        "# ...\n",
        "# must be a .txt file\n",
        "\n",
        "# save_file_path - path to the file where the posed questions and respective retrieved answers are to be saved\n",
        "# must be a .txt file"
      ],
      "metadata": {
        "id": "O3JwFK0s3APs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_paths = # ['file_path_1', 'file_path_2']\n",
        "files_names = # ['files_name_1', 'files_name_2']\n",
        "\n",
        "ix_path = # 'ix_path'\n",
        "questions_file_path = # 'questions_file_path'\n",
        "save_file_path = # 'save_file_path'\n",
        "\n",
        "\n",
        "bert_answers_score(files_paths, files_names, ix_path, questions_file_path, save_file_path, pipe_ques_answering)"
      ],
      "metadata": {
        "id": "m2WkfneJ3ASG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_paths = ['MEO_SmartHome.txt', 'Modem_Huawei_E1750.txt', 'Placa_ZTE_MF63.txt', 'Placa_ZTE_MF65.txt']\n",
        "files_names = ['MEO_SmartHome.txt', 'Modem_Huawei_E1750.txt', 'Placa_ZTE_MF63.txt', 'Placa_ZTE_MF65.txt']\n",
        "\n",
        "ix_path = '/content/'\n",
        "questions_file_path = 'Test_AlticeText.txt'\n",
        "save_file_path = 'Results.txt'\n",
        "\n",
        "\n",
        "bert_answers_score(files_paths, files_names, ix_path, questions_file_path, save_file_path, pipe_ques_answering)"
      ],
      "metadata": {
        "id": "eaPmX-oJsDb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}