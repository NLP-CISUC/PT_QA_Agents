{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_NLI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# BERT - Portuguese Cased NLI\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FG87tbHDntIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iovA4MgUnoIy"
      },
      "outputs": [],
      "source": [
        "# receives\n",
        "# .txt file containing a list of question-answer pairs identified by 'P: ' and 'R: '\n",
        "# .txt file with a list of questions, one question per line\n",
        "\n",
        "# retrieves\n",
        "# .txt file containing the posed questions and respective BERT's answers, identified by 'P: ' and 'R: '"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "qWyGUFt6em8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy\n",
        "import scipy"
      ],
      "metadata": {
        "id": "1vTkLAAkn7d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file management\n",
        "def open_file(filename):\n",
        "    read_file = open(filename, 'r')\n",
        "    file_cont = read_file.readlines()\n",
        "    read_file.close()\n",
        "\n",
        "    return file_cont\n",
        "\n",
        "def write_file(filename, content):\n",
        "    file_write = open(filename, 'w')\n",
        "    file_write.writelines(content)\n",
        "    file_write.close()"
      ],
      "metadata": {
        "id": "VnBkCCaLoAFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1yDb4qCJoB3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT - portuguese cased NLI\n",
        "def bert_model_pt(model_name):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    print('Portuguese Cased NLI Model Downloaded')\n",
        "    return model\n",
        "\n",
        "def get_vector(question, model):\n",
        "    vector = model.encode(question)\n",
        "    return vector"
      ],
      "metadata": {
        "id": "QqA1qvGFoEoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns the answer corresponding to the question in position question_index of question-answer pairs file\n",
        "def get_answer(file_content, question_index):\n",
        "    answer = ''\n",
        "\n",
        "    for i in range(question_index + 1, len(file_content)):\n",
        "        if file_content[i] == '\\n' or 'P: ' in file_content[i]:\n",
        "            break\n",
        "        else:\n",
        "            answer = answer + file_content[i]\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "81_3QqKVrbr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes all questions embeddings, and stores them along with the question position in the domain file\n",
        "def domain_questions_embeddings(domain_content, model):\n",
        "    all_emb = []\n",
        "\n",
        "    for i in range(len(domain_content)):\n",
        "        emb_pos = []\n",
        "\n",
        "        if 'P: ' in domain_content[i]:\n",
        "            aux_ques = domain_content[i].replace('P: ', '')\n",
        "            aux_emb = get_vector(aux_ques, model)\n",
        "\n",
        "            emb_pos.append(aux_emb)\n",
        "            emb_pos.append(i)\n",
        "\n",
        "            all_emb.append(emb_pos)\n",
        "\n",
        "    return all_emb"
      ],
      "metadata": {
        "id": "04O40dutpFqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns position of question in domain most similar to posed question\n",
        "def compute_similarity(all_emb, ques_emb):\n",
        "    cos_sim = -1\n",
        "    pos = 0\n",
        "\n",
        "    for i in range(len(all_emb)):\n",
        "        aux_cos_sim = 1 - scipy.spatial.distance.cosine(all_emb[i][0], ques_emb)\n",
        "\n",
        "        if aux_cos_sim > cos_sim:\n",
        "            cos_sim = aux_cos_sim\n",
        "            pos = all_emb[i][1]\n",
        "\n",
        "    return pos"
      ],
      "metadata": {
        "id": "iUYufgZspO_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieves a file with the posed questions and BERT's answers\n",
        "def bert_portuguese(questions_file_path, domain_file_path, save_file_path):\n",
        "    final_file_content = []\n",
        "    questions = open_file(questions_file_path)\n",
        "    domain_content = open_file(domain_file_path)\n",
        "\n",
        "    model = bert_model_pt('ricardo-filho/bert-portuguese-cased-nli-assin-assin-2')\n",
        "\n",
        "    # creates BERT vector representations of all questions in the domain file\n",
        "    all_emb = domain_questions_embeddings(domain_content, model)\n",
        "\n",
        "    for i in range(len(questions)):\n",
        "\n",
        "        # creates BERT vector representations of posed question\n",
        "        ques_emb = get_vector(questions[i], model)\n",
        "\n",
        "        # returns position of question in domain most similar to posed question\n",
        "        best_match_pos = compute_similarity(all_emb, ques_emb)\n",
        "\n",
        "        # creates the final file containing all posed questions and respective retrieved answers, with 'P: ' and 'R: ' identifiers\n",
        "        aux_ques = 'P: ' + questions[i]\n",
        "        aux_ans = get_answer(domain_content, best_match_pos)\n",
        "\n",
        "        final_file_content.append(aux_ques)\n",
        "        final_file_content.append(aux_ans)\n",
        "        final_file_content.append('\\n')\n",
        "\n",
        "    write_file(save_file_path, final_file_content)\n",
        "    print('File with posed questions and respective answers created!')"
      ],
      "metadata": {
        "id": "r4dl0zcMo8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES\n",
        "\n",
        "# domain_file_path - path to the file containing the domain\n",
        "# must be a file containing question-answer pairs identified with 'P: ' and 'R: ', respectively\n",
        "# FAQs                      \n",
        "# P: question1             \n",
        "# R: answer1           \n",
        "# \\n                        \n",
        "# P: question2              \n",
        "# R: answer2                \n",
        "# \\n                       \n",
        "# must be a .txt file\n",
        "\n",
        "# questions_file_path - path to the file containing all questions, one question per line\n",
        "# Q1\n",
        "# Q2\n",
        "# Q3\n",
        "# ...\n",
        "# must be a .txt file\n",
        "\n",
        "# save_file_path - path to the file where the posed questions and respective retrieved answers are to be saved\n",
        "# must be a .txt file"
      ],
      "metadata": {
        "id": "wsC-Io1SrwCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domain_file_path = # 'domain_file_path'\n",
        "questions_file_path = # 'questions_file_path'\n",
        "save_file_path = # 'save_file_path'\n",
        "\n",
        "bert_portuguese(questions_file_path, domain_file_path, save_file_path)"
      ],
      "metadata": {
        "id": "ozdYRDKUrwFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}